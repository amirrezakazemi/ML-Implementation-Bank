{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def confusion_matrix_metrics(y_true, y_pred):\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "def accuracy(TP, TN, FP, FN):\n",
    "    return (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "def precision(TP, FP):\n",
    "    return TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "\n",
    "def recall(TP, FN):\n",
    "    return TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    return 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at iteration 0: 0.6931471805599453\n",
      "Cost at iteration 100: 0.417733470663037\n",
      "Cost at iteration 200: 0.31957830938342935\n",
      "Cost at iteration 300: 0.2667029335288293\n",
      "Cost at iteration 400: 0.2335126167481712\n",
      "Cost at iteration 500: 0.21049444572851583\n",
      "Cost at iteration 600: 0.1934164669963105\n",
      "Cost at iteration 700: 0.1801235441879058\n",
      "Cost at iteration 800: 0.16940277142923932\n",
      "Cost at iteration 900: 0.16051786274317126\n",
      "Predictions: [False False False False  True  True  True  True]\n",
      "Confusion Matrix:\n",
      "TP: 4, TN: 4, FP: 0, FN: 0\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.theta = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def cost_function(self, h, y):\n",
    "        m = len(y)\n",
    "        return (-1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "    \n",
    "    def get_grad(self, X, y, h):\n",
    "        n = X.shape[0]\n",
    "        grad = (X.T @ (h - y)) / n\n",
    "\n",
    "        return grad\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        X: (n, d)\n",
    "        y: (n, )\n",
    "\n",
    "        output:\n",
    "        theta: (d,)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        n, d = X.shape\n",
    "        self.theta = np.zeros(d+1)\n",
    "\n",
    "        X = np.hstack((np.ones((n, 1)), X))\n",
    "\n",
    "        for _ in range(self.num_iterations):\n",
    "            z = X @ self.theta\n",
    "            h = self.sigmoid(z)\n",
    "            gradient = self.get_grad(X, y, h)\n",
    "            self.theta -= self.learning_rate * gradient\n",
    "\n",
    "            # Optional: print cost to monitor training progress\n",
    "            if _ % 100 == 0:\n",
    "                print(f'Cost at iteration {_}: {self.cost_function(h, y)}')\n",
    "\n",
    "    def predict_prob(self, X):\n",
    "        n = X.shape[0]\n",
    "        X = np.hstack((np.ones((n, 1)), X))\n",
    "        return self.sigmoid(X @ self.theta)\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        return self.predict_prob(X) >= threshold\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Sample dataset\n",
    "X = np.array([[0.5, 1.5], [1.0, 2.0], [1.5, 2.5], [2.0, 3.0], [2.5, 3.5], [3.0, 4.0], [3.5, 4.5], [4.0, 5.0]])\n",
    "y = np.array([0, 0, 0, 0, 1, 1, 1, 1])\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LogisticRegression(learning_rate=0.1, num_iterations=1000)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predicting\n",
    "predictions = model.predict(X)\n",
    "print(f'Predictions: {predictions}')\n",
    "\n",
    "# Compute metrics based on the predictions\n",
    "TP, TN, FP, FN = confusion_matrix_metrics(y, predictions)\n",
    "\n",
    "# Calculate each metric\n",
    "accuracy_value = accuracy(TP, TN, FP, FN)\n",
    "precision_value = precision(TP, FP)\n",
    "recall_value = recall(TP, FN)\n",
    "f1_score_value = f1_score(precision_value, recall_value)\n",
    "\n",
    "# Print the results\n",
    "print(f'Confusion Matrix:\\nTP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}')\n",
    "print(f'Accuracy: {accuracy_value:.2f}')\n",
    "print(f'Precision: {precision_value:.2f}')\n",
    "print(f'Recall: {recall_value:.2f}')\n",
    "print(f'F1 Score: {f1_score_value:.2f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('GRL-DTA-YVPbGvek')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e58127e463989fa099f6aa560686f307565ac6fb929ad63eb0ce9728b1eacef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
